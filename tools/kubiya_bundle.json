{
  "tools": [
    {
      "name": "fastly_realtime",
      "source": null,
      "alias": null,
      "description": "As an intelligent agent named Fastly Realtime, you have the capability to interact with Fastly services.",
      "type": "docker",
      "content": "\npip install requests slack_sdk fuzzywuzzy argparse python-Levenshtein > /dev/null 2>&1\n\npython /tmp/fastly_realtime.py --service_name \"$service_name\" --environment \"$environment\" \n",
      "content_url": null,
      "args": [
        {
          "name": "service_name",
          "type": null,
          "description": "The name of the Fastly service to monitor",
          "required": true,
          "default": null,
          "options": null,
          "options_from": null
        },
        {
          "name": "environment",
          "type": null,
          "description": "The environment to monitor (production, dev, qa)",
          "required": true,
          "default": null,
          "options": null,
          "options_from": null
        }
      ],
      "env": [
        "SLACK_CHANNEL_ID",
        "SLACK_THREAD_TS"
      ],
      "secrets": [
        "FASTLY_API_TOKEN",
        "SLACK_API_TOKEN"
      ],
      "dependencies": null,
      "dependencies_url": null,
      "openapi": null,
      "with_files": [
        {
          "source": null,
          "destination": "/tmp/fastly_realtime.py",
          "content": "#!/usr/bin/env python3\n\nimport os\nimport requests\nimport json\nfrom datetime import datetime, timedelta\nfrom fuzzywuzzy import process, fuzz\nfrom pprint import pprint\nimport time\nimport re\nfrom slack_sdk import WebClient\nfrom slack_sdk.errors import SlackApiError\nimport argparse\n\nVALID_ENVIRONMENTS = ['production', 'dev', 'qa']\nAPI_TOKEN = os.getenv(\"FASTLY_API_TOKEN\")\nSLACK_API_TOKEN = os.getenv(\"SLACK_API_TOKEN\")\nSLACK_CHANNEL_ID = os.getenv(\"SLACK_CHANNEL_ID\")\nSLACK_THREAD_TS = os.getenv(\"SLACK_THREAD_TS\")\nCACHE_FILE = \"services_cache.json\"\nFIELDS_CACHE_FILE = \"fields_cache.json\"\nCACHE_EXPIRY_HOURS = 24\nTIME_UNITS = ['second', 'seconds', 'minute', 'minutes', 'hour', 'hours', 'day', 'days', 'week', 'weeks', 'month', 'months']\nFUZZY_MATCH_THRESHOLD = 80\nREAL_TIME_BASE_URL = \"https://rt.fastly.com\"\nHISTORICAL_BASE_URL = \"https://api.fastly.com\"\nDEFAULT_STREAM_DURATION = 60\nDEFAULT_WAIT_INTERVAL = 1\nFASTLY_DASHBOARD_REALTIME_URL = \"https://manage.fastly.com/observability/dashboard/system/overview/realtime/{service_id}?range={range}\"\n\nCOMMON_FIELDS = [\"status_5xx\", \"requests\", \"hits\", \"miss\", \"all_pass_requests\"]\n\ndef debug_print(message):\n    if os.getenv(\"KUBIYA_DEBUG\"):\n        print(message)\n\ndef load_cache(cache_file):\n    try:\n        if os.path.exists(cache_file):\n            with open(cache_file, 'r') as f:\n                cache_data = json.load(f)\n                cache_timestamp = datetime.fromisoformat(cache_data['timestamp'])\n                if datetime.utcnow() - cache_timestamp < timedelta(hours=CACHE_EXPIRY_HOURS):\n                    return cache_data['data']\n    except Exception as e:\n        print(f\"Error loading cache from {cache_file}: {e}\")\n    return None\n\ndef save_cache(cache_file, data):\n    try:\n        cache_data = {\n            'timestamp': datetime.utcnow().isoformat(),\n            'data': data\n        }\n        with open(cache_file, 'w') as f:\n            json.dump(cache_data, f)\n    except Exception as e:\n        print(f\"Error saving cache to {cache_file}: {e}\")\n\ndef list_services():\n    cached_services = load_cache(CACHE_FILE)\n    if cached_services:\n        debug_print(\"Loaded services from cache.\")\n        return cached_services\n\n    url = f\"{HISTORICAL_BASE_URL}/service\"\n    headers = {\n        \"Fastly-Key\": API_TOKEN,\n        \"Accept\": \"application/json\"\n    }\n    params = {\n        \"direction\": \"ascend\",\n        \"page\": 1,\n        \"per_page\": 20,\n        \"sort\": \"created\"\n    }\n    \n    all_services = {}\n    \n    try:\n        while True:\n            response = requests.get(url, headers=headers, params=params)\n            response.raise_for_status()\n            services = response.json()\n            if not services:\n                break\n            for service in services:\n                all_services[service['name']] = service['id']\n            params[\"page\"] += 1\n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching services from Fastly API: {e}\")\n    \n    save_cache(CACHE_FILE, all_services)\n    return all_services\n\ndef construct_service_prefix(service_name, environment):\n    if environment == 'production':\n        return service_name\n    return f\"{environment}.{service_name.replace(' ', '')}\"\n\ndef get_environment(env_name):\n    if not env_name:\n        return None\n    env_name = env_name.lower()\n    if env_name in VALID_ENVIRONMENTS:\n        return env_name\n    return None\n\ndef get_real_time_data(api_token, service_id, duration_seconds=5):\n    url = f\"{REAL_TIME_BASE_URL}/v1/channel/{service_id}/ts/0\"\n    debug_print(f\"Real-Time API URL: {url}\")\n    headers = {\n        \"Fastly-Key\": api_token,\n        \"Accept\": \"application/json\"\n    }\n    \n    try:\n        debug_print(\"Retrieving real-time data...\")\n        response = requests.get(url, headers=headers)\n        response.raise_for_status()\n        real_time_data = response.json()\n        return real_time_data['Data']\n    except requests.exceptions.RequestException as e:\n        print(f\"Error retrieving real-time data from Fastly API: {e}\")\n        return None\n\n# def get_best_match(prefix, services):\n#     results = process.extract(prefix, services, scorer=fuzz.WRatio)\n#     filtered_results = [result for result in results if result[0].startswith(prefix)]\n#     if not filtered_results:\n#         best_match = max(results, key=lambda x: x[1])\n#     else:\n#         best_match = max(filtered_results, key=lambda x: x[1])\n#     return best_match[0] if best_match else None\n\n# def filter_services_by_environment(environment, services):\n#     # Filter services to those that start with the specified environment\n#     environment_prefix = f\"{environment}.\"\n#     environment_hyphen = f\"{environment}-\"\n#     return {name: service_id for name, service_id in services.items() if name.startswith(environment_prefix) or name.startswith(environment_hyphen)}\n\ndef filter_services_by_environment(environment, services):\n    if environment == 'production':\n        # For production, return services that don't start with 'dev.' or 'qa.'\n        return {name: service_id for name, service_id in services.items() \n                if not name.startswith('dev.') and not name.startswith('qa.')}\n    else:\n        # For dev and qa, keep the existing logic\n        environment_prefix = f\"{environment}.\"\n        environment_hyphen = f\"{environment}-\"\n        return {name: service_id for name, service_id in services.items() \n                if name.startswith(environment_prefix) or name.startswith(environment_hyphen)}\n\n# def get_best_match(service_name, filtered_services):\n#     # Perform fuzzy matching on the filtered list of services\n#     results = process.extract(service_name, filtered_services.keys(), scorer=fuzz.WRatio)\n    \n#     if not results:\n#         raise ValueError(f\"No services found that match '{service_name}'.\")\n    \n#     # Return the best match from the filtered results\n#     best_match = max(results, key=lambda x: x[1])[0]\n#     return best_match\n\ndef get_best_match(service_name, filtered_services, environment):\n    if environment == 'production':\n        # For production, look for an exact match first\n        for name in filtered_services.keys():\n            if name.startswith(service_name + '.'):\n                return name\n\n    # If no exact match found for production or for other environments, perform fuzzy matching\n    results = process.extract(service_name, filtered_services.keys(), scorer=fuzz.WRatio)\n    \n    if not results:\n        raise ValueError(f\"No services found that match '{service_name}' in the '{environment}' environment.\")\n    \n    # Return the best match from the filtered results\n    best_match = max(results, key=lambda x: x[1])[0]\n    return best_match\n\ndef format_value(value):\n    try:\n        value = float(value)  # Ensure the value is a number\n        if value >= 1000:\n            return f\"{value / 1000:.1f}K ({int(value)})\"\n        return str(int(value))\n    except (ValueError, TypeError):\n        return str(value)\n\ndef send_slack_message(channel, thread_ts, blocks, text=\"Message from script\"):\n    client = WebClient(token=SLACK_API_TOKEN)\n    try:\n        response = client.chat_postMessage(channel=channel, thread_ts=thread_ts, blocks=blocks, text=text)\n        return response[\"channel\"], response[\"ts\"]\n    except SlackApiError as e:\n        print(f\"Error sending message to Slack: {e.response['error']}\")\n        return None\n\ndef update_slack_message(channel, ts, blocks, text=\"Updated message from script\", thread_ts=None):\n    client = WebClient(token=SLACK_API_TOKEN)\n    try:\n        if thread_ts:\n            client.chat_update(channel=channel, ts=ts, thread_ts=thread_ts, blocks=blocks, text=text)\n        else:\n            client.chat_update(channel=channel, ts=ts, blocks=blocks, text=text)\n    except SlackApiError as e:\n        print(f\"Error updating message on Slack: {e.response['error']}\")\n\ndef generate_dashboard_url(service_id, range_str):\n    return FASTLY_DASHBOARD_REALTIME_URL.format(service_id=service_id, range=range_str)\n\ndef generate_slack_blocks(summary, interval_summary, service_name, environment, service_id, previous_interval_summary=None):\n    blocks = [\n        {\n            \"type\": \"header\",\n            \"text\": {\n                \"type\": \"plain_text\",\n                \"text\": \":bar_chart: Real-Time Data Summary\"\n            }\n        },\n        {\n            \"type\": \"section\",\n            \"fields\": [\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Service Name:*\\n<{generate_dashboard_url(service_id, '1m')}|{service_name}>\"\n                },\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Environment:*\\n{environment.title()}\"\n                },\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Update Frequency:*\\nEvery 1 second\"\n                }\n            ]\n        },\n        {\"type\": \"divider\"}\n    ]\n\n    for field, value in summary.items():\n        interval_value = interval_summary.get(field, 0)\n        previous_value = previous_interval_summary.get(field, 0) if previous_interval_summary else 0\n        change_emoji = \"\"\n        if interval_value > previous_value:\n            change_emoji = \" :arrow_up:\"\n        elif interval_value < previous_value:\n            change_emoji = \" :small_red_triangle_down:\"\n\n        blocks.append({\n            \"type\": \"section\",\n            \"fields\": [\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*{field.replace('_', ' ').title()}*\\n*Last Interval:* `{format_value(interval_value)}` {change_emoji}\"\n                }\n            ]\n        })\n\n    blocks.append({\n        \"type\": \"section\",\n        \"text\": {\n            \"type\": \"mrkdwn\",\n            \"text\": \"_You can stop the stream by clicking on the 'Stop' button on this thread._\"\n        }\n    })\n\n    return blocks\n\ndef generate_final_slack_blocks_with_intervals(summary, interval_summary, service_name, environment, service_id):\n    blocks = [\n        {\n            \"type\": \"header\",\n            \"text\": {\n                \"type\": \"plain_text\",\n                \"text\": \":bar_chart: Final Real-Time Data Summary\"\n            }\n        },\n        {\n            \"type\": \"section\",\n            \"fields\": [\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Service Name:*\\n<{generate_dashboard_url(service_id, '1m')}|{service_name}>\"\n                },\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Environment:*\\n{environment.title()}\"\n                },\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*Update Frequency:*\\nEvery 1 second\"\n                }\n            ]\n        },\n        {\"type\": \"divider\"}\n    ]\n\n    for field, value in summary.items():\n        interval_value = interval_summary.get(field, 0)\n        blocks.append({\n            \"type\": \"section\",\n            \"fields\": [\n                {\n                    \"type\": \"mrkdwn\",\n                    \"text\": f\"*{field.replace('_', ' ').title()}*\\n*Last Interval:* `{format_value(interval_value)}`\"\n                }\n            ]\n        })\n\n    return blocks\n\ndef stream_real_time_data(api_token, service_name, environment, service_id, duration, wait_interval, slack_channel, thread_ts):\n    print(f\"Streaming real-time data for {duration} seconds with a wait interval of {wait_interval} seconds...\")\n    end_time = datetime.utcnow() + timedelta(seconds=duration)\n    total_stats = {field: 0 for field in COMMON_FIELDS}\n    previous_stats = {field: 0 for field in COMMON_FIELDS}\n\n    slack_ts = None\n    if slack_channel:\n        blocks = generate_slack_blocks(total_stats, {}, service_name, environment, service_id)\n        channel, slack_ts = send_slack_message(slack_channel, thread_ts, blocks)\n    \n    try:\n        while datetime.utcnow() < end_time:\n            time.sleep(wait_interval)\n            stats_data = get_real_time_data(api_token, service_id, duration_seconds=wait_interval)\n            if not stats_data:\n                print(\"Unable to retrieve real-time data.\")\n                return\n\n            interval_stats = {field: 0 for field in COMMON_FIELDS}\n            for data_point in stats_data:\n                for common_field in COMMON_FIELDS:\n                    if common_field in data_point['aggregated']:\n                        interval_stats[common_field] += data_point['aggregated'][common_field]\n\n            for field in COMMON_FIELDS:\n                total_stats[field] += interval_stats[field]\n\n            if slack_channel:\n                blocks = generate_slack_blocks(total_stats, interval_stats, service_name, environment, service_id, previous_interval_summary=previous_stats)\n                update_slack_message(channel, slack_ts, blocks, thread_ts=thread_ts)\n                previous_stats = interval_stats.copy()\n            else:\n                print(f\"\\nReal-Time Data Summary (Last {wait_interval} seconds):\")\n                for field, value in interval_stats.items():\n                    print(f\"{field}: {format_value(value)}\")\n                print(\"\\n---\\n\")\n\n        if not slack_channel:\n            print(\"\\nTotal Real-Time Data Summary:\")\n            for field, value in total_stats.items():\n                print(f\"{field}: {format_value(value)}\")\n            print(\"\\n---\\n\")\n    finally:\n        if slack_channel and slack_ts:\n            final_blocks = generate_final_slack_blocks_with_intervals(total_stats, previous_stats, service_name, environment, service_id)\n            update_slack_message(slack_channel, slack_ts, final_blocks, thread_ts=thread_ts)\n\ndef main(environment, service_name):\n    try:\n        environment = get_environment(environment)\n        if not environment:\n            print(f\"No matching environment found for '{environment}'. Available environments: {VALID_ENVIRONMENTS}\")\n            return\n\n        debug_print(\"Fetching list of services...\")\n        services = list_services()\n        \n        if not services:\n            print(\"No services found.\")\n            return\n\n        # Filter services by the specified environment\n        filtered_services = filter_services_by_environment(environment, services)\n        \n        # Get the best match within the filtered services\n        best_match = get_best_match(service_name, filtered_services, environment)\n        if not best_match:\n            print(f\"No matching service found for '{service_name}' in the '{environment}' environment.\")\n            return\n\n        service_id = services[best_match]\n        debug_print(f\"Best matching service: {best_match}\")\n\n        stream_real_time_data(API_TOKEN, best_match, environment, service_id, DEFAULT_STREAM_DURATION, DEFAULT_WAIT_INTERVAL, SLACK_CHANNEL_ID, SLACK_THREAD_TS)\n        print(f\"View more details in the Fastly dashboard: {generate_dashboard_url(service_id, f'{DEFAULT_STREAM_DURATION}s')}\")\n\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Retrieve Fastly service data.\")\n    parser.add_argument(\"--environment\", required=True)\n    parser.add_argument(\"--service_name\", required=True)\n\n    args = parser.parse_args()\n    main(args.environment, args.service_name)\n"
        }
      ],
      "with_services": [],
      "with_git_repo": null,
      "with_volumes": [],
      "entrypoint": [],
      "icon_url": null,
      "image": "python:3.11-slim",
      "long_running": false,
      "on_start": null,
      "on_complete": null,
      "mermaid": "graph TD\n    %% Styles\n    classDef triggerClass fill:#3498db,color:#fff,stroke:#2980b9,stroke-width:2px,font-weight:bold\n    classDef paramClass fill:#2ecc71,color:#fff,stroke:#27ae60,stroke-width:2px\n    classDef execClass fill:#e74c3c,color:#fff,stroke:#c0392b,stroke-width:2px,font-weight:bold\n    classDef envClass fill:#f39c12,color:#fff,stroke:#f1c40f,stroke-width:2px\n\n    %% Main Components\n    Trigger(\"Trigger\"):::triggerClass\n    Params(\"Parameters\"):::paramClass\n    Exec(\"fastly_realtime\"):::execClass\n    Env(\"Environment\"):::envClass\n\n    %% Flow\n    Trigger --> Params --> Exec\n    Env --> Exec\n\n    %% Trigger Options\n    User(\"User\")\n    API(\"API\")\n    Webhook(\"Webhook\")\n    Cron(\"Scheduled\")\n    User --> Trigger\n    API --> Trigger\n    Webhook --> Trigger\n    Cron --> Trigger\n\n    %% Parameters\n    subgraph Parameters[\"Parameters\"]\n        direction TB\n        Param0(\"service_name (Required)<br/>The name of the Fastly service to monitor\"):::paramClass\n        Param1(\"environment (Required)<br/>The environment to monitor (production, dev, qa)\"):::paramClass\n    end\n    Parameters --- Params\n\n    %% Execution\n    subgraph Execution[\"Execution\"]\n        direction TB\n        Code(\"Script: <br/>pip install requests slack_sdk fuzzywuzzy argpars...\")\n        Type(\"Type: Docker\")\n        Image(\"Docker Image: python:3.11-slim\")\n    end\n    Execution --- Exec\n\n    %% Environment\n    subgraph Environment[\"Environment\"]\n        direction TB\n        EnvVars(\"Environment Variables:<br/>SLACK_CHANNEL_ID<br/>SLACK_THREAD_TS\"):::envClass\n        Secrets(\"Secrets:<br/>FASTLY_API_TOKEN<br/>SLACK_API_TOKEN\"):::envClass\n    end\n    Environment --- Env\n\n    %% Context Note\n    ContextNote(\"Parameter values can be<br/>fetched from context<br/>based on the trigger\")\n    ContextNote -.-> Params",
      "workflow": false,
      "metadata": {}
    }
  ],
  "errors": [],
  "python_bundle_version": "3.11.9"
}